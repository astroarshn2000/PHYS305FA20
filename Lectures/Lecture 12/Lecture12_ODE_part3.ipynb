{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Announcements\n",
    "- No Problem Set this week, Problem Set 4 will be posted on 9/28.\n",
    "- Stay on at the end of lecture if you want to ask questions about Problem Set 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "@import url(https://www.numfys.net/static/css/nbstyle.css);\n",
    "</style>\n",
    "<a href=\"https://www.numfys.net\"><img class=\"logo\" /></a>\n",
    "\n",
    "# Ordinary Differential Equations - higher order methods\n",
    "\n",
    "<section class=\"post-meta\">\n",
    "Based on notes and notebooks by Niels Henrik Aase, Thorvald Ballestad, Vasilis Paschalidis and Jon Andreas St√∏vneng\n",
    "</section>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms for initial value problem ODEs\n",
    "\n",
    "\n",
    "Assume we have a first-order differential equation which can be expressed in the form\n",
    "\n",
    "$$ \\frac{dy}{dt} = g(y,t) $$\n",
    "\n",
    "We will solve this on constant-interval mesh of the independent variable $t$ defined by\n",
    "\n",
    "$$ t_n = t_0 + n h $$\n",
    "\n",
    "### Forward-Euler method\n",
    "\n",
    "In Lecture 10 we derived Euler's method, which simply solves the first-order forward difference approximation to $dy/dt$\n",
    "\n",
    "$$ \\frac{y_{i+1}-y_i}{h} = g(y_i,t_i)$$\n",
    "\n",
    "as\n",
    "\n",
    "$$ y_{i+1} = y_i + h g(y_i,t_i) \\label{Euler_fwd}\\tag{3}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "import numpy as np # NumPy is used to generate arrays and to perform some mathematical operations\n",
    "import matplotlib.pyplot as plt # Used for plotting results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardEuler_step(t, y, h, g, *P):\n",
    "    \"\"\"\n",
    "    Implements a single step of the forward-Euler finite-difference scheme\n",
    "    Parameters:\n",
    "            t: time t\n",
    "            y: Numerical approximation of y at time t\n",
    "            h: Step size\n",
    "            g: RHS of our ODE (RHS = Right hand side). Can be any function with signature g(t,y,*P).\n",
    "            *P: tuple of parameters, arguments to g\n",
    "        Returns:\n",
    "            next_y: Numerical approximation of y at time t+h\n",
    "    \"\"\"\n",
    "    next_y = y + h*g(t, y, *P)\n",
    "    return next_y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need some sort of framework which will take this function and do the integration for us. Let's rewrite `full_Euler` from Lecture 10 to be more general:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odeSolve(t0, y0, tmax, h, g, method, *P):\n",
    "    \"\"\" A full numerical aproximation of an ODE in a set time interval. Performs consecutive steps of `method`\n",
    "    with step size h from start time until the end time. Also takes into account the initial values of the ODE\n",
    "    \n",
    "    Parameters:\n",
    "            t0: start time\n",
    "            y0 : Initial condition for y at t = t0\n",
    "            tmax: The end of the interval where the `method` is integrated, t_N\n",
    "            h: Step size\n",
    "            g: RHS of our ODE (RHS = Right hand side). Can be any function with signature g(t,y,*P).\n",
    "            *P: tuple of parameters, arguments to g\n",
    "        Returns:\n",
    "            t_list: Evenly spaced discrete list of time with spacing h. \n",
    "                    Starting time = start_t, and end time = end_t \n",
    "            y_list: Numerical approximation of y at times t_list\n",
    "    \"\"\"    \n",
    "    # make the t-mesh; guarantees we stop precisely at tmax\n",
    "    t_list = np.arange(t0,tmax+h,h)\n",
    "    # allocate space for the solution\n",
    "    y_list = np.zeros_like(t_list)\n",
    "    # set the initial condition\n",
    "    y_list[0] = y0\n",
    "    \n",
    "    # find out the size of the t-mesh, and then integrate forward one meshpoint per iteration of the loop\n",
    "    n, = t_list.shape\n",
    "    for i in range(0,n-1):\n",
    "        y_list[i+1] = method(t_list[i], y_list[i], h, g, *P)\n",
    "        \n",
    "    # return the solution\n",
    "    return t_list,y_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Armed with this machinery, let's set up another simple problem and try it out.\n",
    "\n",
    "Last time, we looked at exponential growth, let's solve exponential decay this time:\n",
    "\n",
    "$$ \\frac{dy}{dt} = - c y, \\quad y[0] = 1 $$\n",
    "\n",
    "First, we provide a function to implement the RHS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expRHS(t, y, c):\n",
    "    \"\"\"\n",
    "    Implements the RHS (y'(x)) of the DE\n",
    "    \"\"\"\n",
    "    return -c*y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set up the problem to compute and plot the result, along with a plot of the magnitude of the fractional error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runge-Kutta Schemes\n",
    "\n",
    "The idea of the Runge-Kutta schemes is to take advantage of derivative information at the times between $t_i$ and $t_{i+1}$ to increase the order of accuracy.\n",
    "\n",
    "For example, in the midpoint method, the derivative at the initial time is used to approximate the derivative at the midpoint of the interval, $f(y_i+\\frac{1}{2}hf(y_i,t_i), t_i+\\frac{1}{2}h)$. The derivative at the midpoint is then used to advance the solution to the next step. The method can be written in two stages $k_i$,\n",
    "\n",
    "$$ \\begin{aligned} \\begin{array}{l} k_1 = h f(y_i,t_i)\\\\ k_2 = h f(y_i+\\frac{1}{2}k_1, t_n+\\frac{1}{2}h)\\\\ y_{i+1} = y_i + k_2 \\end{array} \\end{aligned}\\label{RK2}\\tag{4} $$\n",
    "\n",
    "The midpoint method is known as a __2nd-order Runge-Kutta__ formula.\n",
    "\n",
    "\n",
    "In general, an explicit 2-stage Runge-Kutta method can be written as,\n",
    "$$ \\begin{array}{l} k_1 = h f(y_n,t_n)\\\\ k_2 = h f(y_n+b_{21}k_1, t_n+a_2h)\\ \\\\ y_{n+1} = y_n + c_1k_1 +c_2k_2 \\label{explicitrk2}\\tag{5}\\end{array} $$\n",
    "\n",
    "The scheme is said to be *explicit* since a given stage does not depend *implicitly* on itself, as in the backward Euler method , or on a later stage.\n",
    "\n",
    "Other explicit second-order schemes can be derived by comparing Eq.(\\ref{explicitrk2}) to other second-order expansions and matching terms to determine the coefficients $a_2$, $b_{21}$, $c_1$ and $c_2$.\n",
    "\n",
    "### Explicit Fourth-Order Runge-Kutta Method\n",
    "\n",
    "Explicit Runge-Kutta methods are popular as each stage can be calculated with one function evaluation. In contrast, implicit Runge-Kutta methods usually involves solving a non-linear system of equations in order to evaluate the stages. As a result, explicit schemes are much less expensive to implement than implicit schemes.\n",
    "\n",
    "The higher-order Runge-Kutta methods can be derived by in manner similar to the midpoint formula. An s-stage method is compared to a Taylor method and the terms are matched up to the desired order.\n",
    "\n",
    "As it happens to be, <strong>The Fourth Order Runge-Kutta Method</strong> uses three such test-points and is the most widely used Runge-Kutta Method. You might ask why we don't use five, ten or even more test-points, and the answer is quite simple: It is not computationally free to calculate all these test-points, and the gain in accuracy rapidly decreases beyond the fourth order of the method. That is, if high precision is of such importance that you would require a tenth-order Runge-Kutta, then you're better off reducing the step size $h$, than increasing the order of the method. \n",
    "\n",
    "Also, there exists other more sophisticated methods which can be both faster and more accurate for equivalent choices of $h$, but obviously, may be a lot more complicated to implement. See for instance <i>Richardson Extrapolation</i>, <i>the Bulirsch-Stoer method</i>, <i>Multistep methods, Multivalue methods</i> and <i>Predictor-Corrector methods</i>.\n",
    "\n",
    "\n",
    "The classic fourth-order Runge-Kutta formula is:\n",
    "$$ \\begin{array}{l} k_1 = h f(y_n,t_n)\\\\ k_2 = h f(y_n+\\frac{k_1}{2}, t_n+\\frac{h}{2})\\\\ k_3 = h f(y_n+\\frac{k_2}{2}, t_n+\\frac{h}{2})\\\\ k_4 = h f(y_n+k_3, t_n+h)\\\\ y_{n+1} = y_n + \\frac{k_1}{6}+ \\frac{k_2}{3}+ \\frac{k_3}{3} + \\frac{k_4}{6} \\label{RK4}\\tag{6}\\end{array} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RK2_step(t, y, h, g, *P):\n",
    "    \"\"\"\n",
    "    Implements a single step of the second-order, explicit midpoint method\n",
    "    \"\"\"\n",
    "    thalf = t + 0.5*h\n",
    "    k1 = h * g(t, y, *P)\n",
    "    k2 = h * g(thalf, y + 0.5*k1, *P)\n",
    "\n",
    "    return y +k2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RK4_step(t, y, h, g, *P):\n",
    "    \"\"\"\n",
    "    Implements a single step of a fourth-order, explicit Runge-Kutta scheme\n",
    "    \"\"\"\n",
    "    thalf = t + 0.5*h\n",
    "    k1 = h * g(t, y, *P)\n",
    "    k2 = h * g(thalf, y + 0.5*k1, *P)\n",
    "    k3 = h * g(thalf, y + 0.5*k2, *P)\n",
    "    k4 = h * g(t + h, y + k3, *P)\n",
    "    return y + (k1 + 2*k2 + 2*k3 + k4)/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up problem\n",
    "c = 1.0\n",
    "h = 0.5\n",
    "t0 = 0.0\n",
    "y0 = 1.0\n",
    "tmax = 5.0\n",
    "\n",
    "# call the solver for RK2\n",
    "t, y = odeSolve(t0, y0, tmax, h, expRHS, RK2_step, c)\n",
    "\n",
    "# plot the result\n",
    "fig,ax = plt.subplots(1,2)\n",
    "ans = np.exp(-c*t)\n",
    "ax[0].plot(t,ans,'r')\n",
    "ax[0].set_xlabel('t')\n",
    "ax[0].set_ylabel('y')\n",
    "\n",
    "ax[0].plot(t,y,'o','RK2')\n",
    "err_RK2 = np.abs((ans-y)/ans)\n",
    "\n",
    "# call the solver for Euler\n",
    "t, y = odeSolve(t0, y0, tmax, h, expRHS, forwardEuler_step, c)\n",
    "ax[0].plot(t,y,'o','Euler')\n",
    "err = np.abs((ans-y)/ans)\n",
    "\n",
    "# call the solver for RK2\n",
    "t, y4 = odeSolve(t0, y0, tmax, h, expRHS, RK4_step, c)\n",
    "ax[0].plot(t,y4,'o','RK4')\n",
    "err_RK4 = np.abs((ans-y4)/ans)\n",
    "\n",
    "# along with the errors\n",
    "err_RK2 = np.abs((ans-y)/ans)\n",
    "ax[1].plot(t, err_RK2, 'o',label = \"RK2\")\n",
    "ax[1].plot(t, err_RK4, 'o',label = \"RK4\")\n",
    "ax[1].plot(t, err, 'o',label = \"Euler\")\n",
    "ax[1].set_xlabel('t')\n",
    "ax[1].set_ylabel('fractional error')\n",
    "ax[1].legend()\n",
    "# now also overplot the error we calculated for forward-Euler\n",
    "\n",
    "# this gives better spacing between axes\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Systems of First-Order ODEs\n",
    "\n",
    "Next, we turn to systems of ODE's. We'll take as our example the Lotke-Volterra equations, a simple model of population dynamics in an ecosystem (with many other uses as well).\n",
    "\n",
    "Imagine a population of rabbits and of foxes on a small island. The rabbits eat a plentiful supply of grass and\n",
    "would breed like, well, rabbits, with their population increasing exponentially with time in the absence of preditors. The foxes eat the rabbits, and would die out exponentially in time with no food supply. The rate at which foxes eat rabbits depends upon the product of the fox and rabbit populations.\n",
    "\n",
    "The equations for the population of the rabbits $R$ and foxes $F$ in this simple model is then\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\frac{dR}{dt} &= \\alpha R - \\beta R F \\\\\n",
    "\\frac{dF}{dt} &= \\delta R F - \\gamma F\n",
    "\\end{eqnarray*}\n",
    "\n",
    "Without the cross terms in $RF$, these are just two decay equations of the form we have used as an example above.\n",
    "\n",
    "A random set of parameters (I am not a biologist!) might be that a rabbit lives four years, so $\\alpha=1/4$ and\n",
    "a fox lives 10 years, so $\\gamma=1/10$. Let's pick the other parameters as $\\beta = 1$ and $\\delta = 1/4$.\n",
    "\n",
    "We can express the unknown populations as a vector of length two: $y = (R, F)$. The rate of change of populations then can also be expressed as a vector $dy/dt = (dR/dt, DF/dt)$. With such a definition, we can write the RHS function of our system as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lvRHS(t, y, *P):\n",
    "    # Lotke-Volterra system RHS\n",
    "    \n",
    "    # unpack the parameters from the array P\n",
    "    alpha, beta, gamma, delta = P\n",
    "\n",
    "    # make temporary variables with rabbit and fox populations\n",
    "    R = y[0]\n",
    "    F = y[1]\n",
    "    \n",
    "    # LV system\n",
    "    dRdt = alpha * R - beta * R * F\n",
    "    dFdt = delta * R * F - gamma * F\n",
    "    \n",
    "    # return an array of derivatives with same order as input vector\n",
    "    return np.array([ dRdt, dFdt ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have to generalize our odeSolve function to allow more than one equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odeSolve(t0, y0, tmax, h, RHS, method, *P):\n",
    "    \"\"\"\n",
    "    ODE driver with constant step-size, allowing systems of ODE's\n",
    "    \"\"\"\n",
    "    # make array of times and find length of array\n",
    "    t = np.arange(t0,tmax+h,h)\n",
    "    ntimes,  = t.shape\n",
    "\n",
    "    # find out if we are solving a scalar ODE or a system of ODEs, and allocate space accordingly\n",
    "    \n",
    "    if type(y0) in [int, float]:  # check if primitive type -- means only one eqn\n",
    "        neqn = 1\n",
    "        y = np.zeros( ntimes )\n",
    "    else:                         # otherwise assume a numpy array -- a system of more than one eqn\n",
    "        neqn, = y0.shape\n",
    "        y = np.zeros( (ntimes, neqn) )\n",
    "\n",
    "    # set first element of solution to initial conditions (possibly a vector) \n",
    "    y[0] = y0\n",
    "\n",
    "    # march on...\n",
    "    for i in range(0,ntimes-1):\n",
    "        y[i+1] = method(t[i], y[i], h, RHS, *P)\n",
    "\n",
    "    return t,y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can solve our system of two coupled ODEs. Note that the solution is now a vector of 2D vectors... the first index is the solution time, the second the variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1.0 \n",
    "beta = 0.025\n",
    "gamma = 0.4\n",
    "delta = 0.01\n",
    "\n",
    "h = 0.2\n",
    "t0 = 0.0\n",
    "y0 = np.array([ 30, 10 ])\n",
    "tmax = 50\n",
    "\n",
    "# call the solver\n",
    "t, y = odeSolve(t0, y0, tmax, h, lvRHS, RK4_step, alpha, beta, gamma, delta)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(t,y[:,0],'b', label='prey')\n",
    "ax.plot(t,y[:,1],'r', label='preditor')\n",
    "ax.set_xlabel('time')\n",
    "ax.set_ylabel('population')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Higher Order Derivatives and Sets of 1st order ODEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trick to solving ODEs with higher derivatives is turning them into systems of first-order ODEs.\n",
    "\n",
    "As a simple example, consider the second-order differential equation describing the van der Pol oscillator\n",
    "\n",
    "$$ \\frac{d^2 x}{dt^2} - a (1-x^2) \\frac{dx}{dt} + x = 0 $$\n",
    "\n",
    "We turn this into a pair of first-order ODEs by defining an auxiliary function $v(t) = dx/dt$ and writing the system as\n",
    "\n",
    "\\begin{align}\n",
    "\\begin{split}\n",
    "\\frac{dv}{dt} &= a (1-x^2) v - x\\\\\n",
    "\\frac{dx}{dt} &= v\n",
    "\\end{split}\n",
    "\\end{align}\n",
    "\n",
    "Note that there are only functions (and the independent variable) on the RHS; all \"differentials\" are on the LHS.\n",
    "\n",
    "Now that we have a system of first-order equations ,we can proceed as above. A function describing\n",
    "the RHS of this system is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vdpRHS(t, y, a):\n",
    "    # we store our function as the array [x, x']\n",
    "    return np.array([\n",
    "        \n",
    "        y[1],                          # dx/dt = v\n",
    "        a*(1-y[0]**2)*y[1] - y[0]      # dv/dt = a*(1-x**2)*v - x\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 15 # parameter\n",
    "\n",
    "h = 0.01\n",
    "t0 = 0.0\n",
    "y0 = np.array([ 0,  1])\n",
    "tmax = 50\n",
    "\n",
    "# call the solver\n",
    "t, y = odeSolve(t0, y0, tmax, h, vdpRHS, RK4_step, a)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(t,y[:,0],'b', label='x')\n",
    "ax.plot(t,y[:,1],'r--', label='v')\n",
    "ax.set_xlabel('time')\n",
    "ax.legend()\n",
    "ax.set_title(f\"van der Pol Oscillator for a={a}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A somewhat more complex example is the Lane-Emden equation, which is really just Poisson's equation in spherical symmetry for the graviational potential of a self-gravitating fluid whose pressure is related to its density as $P\\propto\\rho^\\gamma$. Such a system is called a _polytrope_, and is often used in astrophysics as a simple model for the structure of system such as a a star in which outward pressure and inward gravity are in equilibrium.\n",
    "\n",
    "Let $\\xi$ be the dimensionless radius of the system, and let $\\theta$ be related to the density as\n",
    "$\\rho = \\rho_c \\theta^n$, where $\\rho_c$ is the density at the origin and $n = 1/(\\gamma-1)$. We then have the dimensionless second-order differential equation\n",
    "\n",
    "$$ \\frac{1}{\\xi^2}\\frac{d}{d\\xi}\\left(\\xi^2\\frac{d\\theta}{d\\xi}\\right) + \\theta^n = 0 $$\n",
    "\n",
    "Note that the first term is just the divergence $\\nabla\\cdot\\theta$ in spherical symmetry.\n",
    "\n",
    "If we expand out the first term, we have \n",
    "\n",
    "$$ \\frac{d^2\\theta}{d\\xi^2} + \\frac{2}{\\xi}\\frac{d\\theta}{d\\xi} + \\theta^n = 0 $$\n",
    "\n",
    "Defining an auxiliary function $v(\\xi) = d\\theta/d\\xi$, we can then convert this into a system of two first-order ODEs:\n",
    "\n",
    "\\begin{align}\n",
    "\\begin{split}\n",
    "\\frac{dv}{d\\xi} &= -\\frac{2}{\\xi} v - \\theta^n \\\\\n",
    "\\frac{d\\theta}{d\\xi} &= v\n",
    "\\end{split}\n",
    "\\end{align}\n",
    "\n",
    "Again, we have \"derivatives\" only on the LHS and no derivatives on the RHS of our system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this expression, one can see right away that at the origin $\\xi=0$ we will have a numerical problem; we are dividing by zero.\n",
    "Analytically, this is not a problem, since $v/\\xi\\rightarrow0$ as $\\xi\\rightarrow0$, but here we need to address this numerically.\n",
    "\n",
    "The first approach is to take care of the problem in our RHS function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leRHS(x, y, n):\n",
    "    \n",
    "    dthetadx = y[1]\n",
    "    \n",
    "    if x==0:\n",
    "        dvdx = -y[0]**n\n",
    "    else:\n",
    "        dvdx = -2/x*y[1] - y[0]**n\n",
    "    \n",
    "    return np.array([ dthetadx, dvdx ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is somewhat clunky, however, and you would first have to convince yourself that in fact $v(\\xi)\\rightarrow0$ faster than $\\xi$ (don't just take my word for it!).\n",
    "\n",
    "Instead, we could use a more direct RHS function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leRHS(x, y, n):\n",
    "    \n",
    "    dthetadx = y[1]\n",
    "    \n",
    "    dvdx = -2/x*y[1] - y[0]**n\n",
    "    \n",
    "    return np.array([ dthetadx, dvdx ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and expand the solution in a Taylor series about the origin to get a starting value for our numerical integration at a small distance away from the origin. To do this, write \n",
    "\n",
    "$$\\theta(\\xi) = a_0 + a_1 \\xi + a_2 \\xi^2 + \\dots$$\n",
    "\n",
    "The first thing to notice is that, by symmetry, only even powers of $\\xi$ will appear in the solution.\n",
    "Thus we will have\n",
    "\n",
    "$$ \\theta(\\xi) = a_0 + a_2 \\xi^2 + a_4 \\xi^4 + \\dots$$\n",
    "\n",
    "By the boundary condition $\\theta(0) = 1$, we have immediately that $a_0 = 1$.\n",
    "\n",
    "Next, substitute $\\theta(\\xi) = 1 + a_2 \\xi^2 + a_4 \\xi ^4 + O(\\xi^6)$ into the Lane-Emden equation. $\\theta$ and its first two derivatives are\n",
    "\n",
    "\\begin{align}\n",
    "\\begin{split}\n",
    "\\theta(\\xi) &= 1 + a_2 \\xi^2 + a_4 \\xi^4 + O(\\xi^6)\\\\\n",
    "\\theta'(\\xi) &= 2 a_2 \\xi + 4 a_4 \\xi^3 + O(\\xi^5) \\\\\n",
    "\\theta''(\\xi) &= 2 a_2 + 12 a_4 \\xi^2 + O(\\xi^4)\n",
    "\\end{split}\n",
    "\\end{align}\n",
    "\n",
    "Putting these into the Lane-Emden equation, we have\n",
    "\\begin{align}\n",
    "\\begin{split}\n",
    "2 a_2 + 12 a_4 \\xi^2 + O(\\xi^4) + \\frac{2}{\\xi} (2 a_2 x + 4 a_4 \\xi^3 + O(\\xi^5))  &= -\\theta^n \\\\\n",
    "6 a_2 + 20 a_4 \\xi^2 + O(\\xi^4) &= -\\theta^n\n",
    "\\end{split}\n",
    "\\end{align}\n",
    "\n",
    "A boundary condition $\\theta(0)=1$, and thus we have $a_2 = -1/6$. Away from zero, then, we have\n",
    "\n",
    "\\begin{align}\n",
    "\\begin{split}\n",
    "-1 + 20 a_4 \\xi^2 + O(\\xi^4) &= -\\left(1 - 1/6 \\xi^2 + a_4 \\xi^4 + O(\\xi^6)\\right)^n\n",
    "\\end{split}\n",
    "\\end{align}\n",
    "\n",
    "The term on the RHS is $ 1 - n \\xi^2/6 + O(\\xi^4)$, and so we must have $a_4 = n/120$.\n",
    "\n",
    "Thus, the series expansion of the solution around the origin is\n",
    "\n",
    "$$ \\theta(\\xi) = 1 - \\frac{1}{6}\\xi^2 + \\frac{n}{120} \\xi^4 + \\dots $$\n",
    "\n",
    "We can now use this expansion to take a first step slightly away from the origin before beginning our\n",
    "numerical integration, thus avoiding the divide by zero. Note that this series solution near the origin is $O(h^5)$ and so is a good match for RK4 if we take the same (or smaller) step-size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "\n",
    "xi0 = 0.01                            # starting value of xi for our numerical integration\n",
    "theta0 = 1 - xi0**2/6 + n*xi0**4/120  # Taylor series solution to the DE near zero derived above\n",
    "theta0p = -xi0/3 + n*xi0**3/30\n",
    "y0 = np.array([ theta0,  theta0p])    # set IC's for numerical integration\n",
    "print(f\"IC at {xi0:10.5e}: {y0[0]:10.5e}, {y0[1]:10.5e}\")\n",
    "\n",
    "h = 0.1\n",
    "tmax = 8\n",
    "\n",
    "# call the solver\n",
    "t, y = odeSolve(xi0, y0, tmax, h, leRHS, RK4_step, n)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(t,y[:,0],'b', label=r'$\\theta(\\xi)$')\n",
    "ax.plot(t,y[:,1],'r--', label=r'$\\frac{d\\theta}{d\\xi}$')\n",
    "ax.plot([0,tmax],[0,0],'k')\n",
    "ax.set_xlabel(r'$\\xi$')\n",
    "ax.set_title(f\"Lane Emden Equation for n={n}\")\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For values of $n\\le5$, the solutions of the Lane Emden equation (the so-called Lane-Emden functions of index $n$) decrease to zero at finite $\\xi$. Since this is the radius at which the density goes to zero, we can interpret it as the surface of the self-gravitating body (for example, the radius of the star). Knowing this value $\\xi_1$ is thus interesting... Let us see how to determine it numerically.\n",
    "\n",
    "Cleary, we are looking for the solution to $\\theta(\\xi_1)=0$; this is just root-finding, which we already know how to do. Instead of using some closed-form function, however, the value of the function $\\theta(\\xi)$ must in this case be determined numerically. But we have just figured out how to do this!\n",
    "\n",
    "Let's use the bisection method for our root-finding algorithm; here is a quick version (no error checking!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisection(func, low, high, eps, *P):\n",
    "    flow = func(low, *P)\n",
    "    fhigh = func(high, *P)\n",
    "    mid = 0.5*(low+high)\n",
    "    fmid = func(mid,*P)\n",
    "    \n",
    "    while (high-low)> eps:\n",
    "        if fmid*flow < 0:\n",
    "            high = mid\n",
    "            fhigh = fmid\n",
    "        else:\n",
    "            low = mid\n",
    "            flow = mid\n",
    "            \n",
    "        mid = 0.5*(low+high)\n",
    "        fmid = func(mid,*P)\n",
    "            \n",
    "    return low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us make a function which returns $\\theta(\\xi)$, the solution to the Lane-Emden equation at $\\xi$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theta(xi, n):\n",
    "    h = 1e-4\n",
    "    xi0 = 1e-4\n",
    "    theta0 = 1 - xi0**2/6 + n*xi0**4/120\n",
    "    theta0p = -xi0/3 + n*xi0**3/30\n",
    "    y0 = np.array([ theta0,  theta0p])\n",
    "    t, y = odeSolve(xi0, y0, xi, h, leRHS, RK4_step, n)\n",
    "    \n",
    "    return y[-1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these, we can compute the surface radius of the polytrope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "xi1 = bisection(theta, 6, 8, 1e-5, n)\n",
    "print(f\"xi_1 = {xi1:7.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more careful treatment gives a value $\\xi_1 = 6.89685...$, so we are doing pretty well..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
